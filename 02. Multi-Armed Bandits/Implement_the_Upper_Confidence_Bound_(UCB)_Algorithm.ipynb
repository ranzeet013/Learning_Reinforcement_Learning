{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITtMPySoJJzT",
        "outputId": "8f5d7a4f-488d-49df-d78b-a60edc289e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Probabilities : [5.82729593e-01 8.16415874e-01 6.81424375e-01 8.73550246e-01\n",
            " 4.89146134e-01 6.34966703e-01 7.75895571e-01 1.74552748e-04\n",
            " 1.41865593e-01 4.47487482e-01]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "number_of_arms = 10\n",
        "number_of_rounds = 1000\n",
        "\n",
        "true_probabilities = np.random.rand(number_of_arms)\n",
        "print(f\"True Probabilities : {true_probabilities}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimated_ucb_reward = np.zeros(number_of_arms)   # estimated reward for each arm\n",
        "ucb_counts = np.zeros(number_of_arms)        # number of times each arm is pulled\n",
        "total_reward_ucb = 0     # total reward obtained\n",
        "rewards_ucb = np.zeros(number_of_rounds)    # rewards obtained at each round\n",
        "cumulative_ucb_regret = np.zeros(number_of_rounds)"
      ],
      "metadata": {
        "id": "LB-09idsKSrJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_arm = np.argmax(true_probabilities)\n",
        "optimal_reward = 0\n",
        "optimal_rewards = np.zeros(number_of_rounds)"
      ],
      "metadata": {
        "id": "nntDDB9qOB3G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ucb algorithms\n",
        "for i in range(number_of_rounds):\n",
        "    if i < number_of_arms:\n",
        "        ucb_arm = i\n",
        "    else:\n",
        "        ucb_values = estimated_ucb_reward + np.sqrt((2 * np.log(i + 1)) / ucb_counts)\n",
        "        ucb_arm = np.argmax(ucb_values)\n",
        "\n",
        "    ucb_reward = np.random.rand() < true_probabilities[ucb_arm]\n",
        "\n",
        "    ucb_counts[ucb_arm] += 1\n",
        "    estimated_ucb_reward[ucb_arm] += (ucb_reward - estimated_ucb_reward[ucb_arm]) / ucb_counts[ucb_arm]\n",
        "\n",
        "    total_reward_ucb += ucb_reward\n",
        "    rewards_ucb[i] = ucb_reward\n",
        "\n",
        "    optimal_rewards[i] = true_probabilities[best_arm]\n",
        "    optimal_reward += optimal_rewards[i]\n",
        "    cumulative_ucb_regret[i] = optimal_reward - total_reward_ucb\n",
        "\n",
        "print(f\"UCB Reward : {np.sum(rewards_ucb)}\")\n",
        "print(f\"Total cumulative regret : {np.sum(cumulative_ucb_regret)}\")\n",
        "print(f\"Total optimal rewards : {np.sum(optimal_rewards)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY6cBWFBLoyp",
        "outputId": "de13bd9c-6b50-4570-f90a-5f9d487068fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UCB Reward : 749.0\n",
            "Total cumulative regret : 66500.89818161968\n",
            "Total optimal rewards : 873.5502461171139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vcXDbqNXOoFK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}