{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8v02NCsafs4t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def value_iteration(states, actions, transitions, rewards, discount_factor, tolerance):\n",
        "    \"\"\"\n",
        "    Perform the Value Iteration algorithm for a given Finite Markov Decision Process (FMDP).\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    states : list\n",
        "        A list of all possible states in the FMDP.\n",
        "\n",
        "    actions : list\n",
        "        A list of all possible actions in the FMDP.\n",
        "\n",
        "    transitions : dict\n",
        "        A dictionary where keys are (state, action, next_state) tuples,\n",
        "        and values are the probabilities of moving to `next_state` from `state`\n",
        "        when taking `action`.\n",
        "\n",
        "    rewards : dict\n",
        "        A dictionary where keys are (state, action, next_state) tuples,\n",
        "        and values are the rewards received after transitioning to `next_state`\n",
        "        from `state` using `action`.\n",
        "\n",
        "    discount_factor : float\n",
        "        A value between 0 and 1 that indicates how much future rewards are valued.\n",
        "\n",
        "    tolerance : float\n",
        "        A small positive number used to determine when to stop the iteration.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    state_values : dict\n",
        "        A dictionary where each key is a state and each value is the estimated value of that state.\n",
        "\n",
        "    best_policy : dict\n",
        "        A dictionary where each key is a state and each value is the best action to take in that state.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the value of each state to zero\n",
        "    state_values = {state: 0 for state in states}\n",
        "\n",
        "    while True:\n",
        "        max_change = 0  # Track the maximum change in the value of any state during this iteration\n",
        "\n",
        "        for state in states:\n",
        "            current_value = state_values[state]  # Store the current value of the state\n",
        "\n",
        "            # Calculate the value for this state by considering all possible actions\n",
        "            new_value = max(\n",
        "                sum(\n",
        "                    transitions.get((state, action, next_state), 0) *\n",
        "                    (rewards.get((state, action, next_state), 0) + discount_factor * state_values[next_state])\n",
        "                    for next_state in states\n",
        "                )\n",
        "                for action in actions\n",
        "            )\n",
        "\n",
        "            # Update the value of the state\n",
        "            state_values[state] = new_value\n",
        "\n",
        "            # Track the maximum difference between old and new values\n",
        "            max_change = max(max_change, abs(current_value - new_value))\n",
        "\n",
        "        # If the values are changing less than the tolerance level, stop iterating\n",
        "        if max_change < tolerance:\n",
        "            break\n",
        "\n",
        "    # Determine the best action for each state based on the computed state values\n",
        "    best_policy = {}\n",
        "    for state in states:\n",
        "        best_action = max(\n",
        "            actions,\n",
        "            key=lambda action: sum(\n",
        "                transitions.get((state, action, next_state), 0) *\n",
        "                (rewards.get((state, action, next_state), 0) + discount_factor * state_values[next_state])\n",
        "                for next_state in states\n",
        "            )\n",
        "        )\n",
        "        best_policy[state] = best_action\n",
        "\n",
        "    return state_values, best_policy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VNRrJ7IjgHwA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}